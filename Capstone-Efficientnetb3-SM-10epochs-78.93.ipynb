{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91182104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import glob \n",
    "import keras\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import skimage.color as scc\n",
    "\n",
    "from skimage import io\n",
    "from random import randint\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator as ID\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam, Adamax\n",
    "# from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f9d57937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "EnvironmentLocationNotFound: Not a conda environment: C:\\Users\\Sriya\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conda install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "211d8877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting np_utils\n",
      "  Downloading np_utils-0.6.0.tar.gz (61 kB)\n",
      "     ---------------------------------------- 62.0/62.0 kB 1.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.0 in c:\\users\\sriya nukala\\anaconda3\\lib\\site-packages (from np_utils) (1.23.5)\n",
      "Building wheels for collected packages: np_utils\n",
      "  Building wheel for np_utils (setup.py): started\n",
      "  Building wheel for np_utils (setup.py): finished with status 'done'\n",
      "  Created wheel for np_utils: filename=np_utils-0.6.0-py3-none-any.whl size=56454 sha256=93e3ed86a17c61397616d22db8edebcb7a0d1e901588f9333a9a250742ef5c5e\n",
      "  Stored in directory: c:\\users\\sriya nukala\\appdata\\local\\pip\\cache\\wheels\\c9\\5e\\52\\216e2fa9b02d46b865d8160e7fe29dcf98f89a2fb7be254877\n",
      "Successfully built np_utils\n",
      "Installing collected packages: np_utils\n",
      "Successfully installed np_utils-0.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba29cab9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.14.0-cp310-cp310-win_amd64.whl (2.1 kB)\n",
      "Collecting tensorflow-intel==2.14.0\n",
      "  Downloading tensorflow_intel-2.14.0-cp310-cp310-win_amd64.whl (284.1 MB)\n",
      "     -------------------------------------- 284.1/284.1 MB 2.9 MB/s eta 0:00:00\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting tensorflow-estimator<2.15,>=2.14.0\n",
      "  Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n",
      "     -------------------------------------- 440.7/440.7 kB 6.8 MB/s eta 0:00:00\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "     ---------------------------------------- 65.5/65.5 kB 3.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\sriya nukala\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (4.24.0)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.6-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "     ---------------------------------------- 24.4/24.4 MB 3.7 MB/s eta 0:00:00\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tensorboard<2.15,>=2.14\n",
      "  Downloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
      "     ---------------------------------------- 5.5/5.5 MB 4.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools in c:\\users\\sriya nukala\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (65.6.3)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "     -------------------------------------- 130.2/130.2 kB 3.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.23.5 in c:\\users\\sriya nukala\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.23.5)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 4.7 MB/s eta 0:00:00\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting ml-dtypes==0.2.0\n",
      "  Downloading ml_dtypes-0.2.0-cp310-cp310-win_amd64.whl (938 kB)\n",
      "     -------------------------------------- 938.6/938.6 kB 5.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\sriya nukala\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (3.7.0)\n",
      "Collecting flatbuffers>=23.5.26\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.59.0-cp310-cp310-win_amd64.whl (3.7 MB)\n",
      "     ---------------------------------------- 3.7/3.7 MB 4.2 MB/s eta 0:00:00\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 57.5/57.5 kB 3.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\sriya nukala\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\sriya nukala\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\sriya nukala\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (4.7.1)\n",
      "Collecting keras<2.15,>=2.14.0\n",
      "  Downloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 4.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\sriya nukala\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\sriya nukala\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.14.0->tensorflow) (0.38.4)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\sriya nukala\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\sriya nukala\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.2.2)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.23.2-py2.py3-none-any.whl (181 kB)\n",
      "     ------------------------------------- 182.0/182.0 kB 10.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\sriya nukala\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.31.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.1-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\sriya nukala\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\sriya nukala\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\sriya nukala\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.2.8)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sriya nukala\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sriya nukala\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sriya nukala\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sriya nukala\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\sriya nukala\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\sriya nukala\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     -------------------------------------- 151.7/151.7 kB 8.8 MB/s eta 0:00:00\n",
      "Installing collected packages: libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, opt-einsum, oauthlib, ml-dtypes, keras, grpcio, google-pasta, gast, astunparse, absl-py, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: google-auth\n",
      "    Found existing installation: google-auth 1.4.2\n",
      "    Uninstalling google-auth-1.4.2:\n",
      "      Successfully uninstalled google-auth-1.4.2\n",
      "Successfully installed absl-py-2.0.0 astunparse-1.6.3 flatbuffers-23.5.26 gast-0.5.4 google-auth-2.23.2 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.59.0 keras-2.14.0 libclang-16.0.6 ml-dtypes-0.2.0 oauthlib-3.2.2 opt-einsum-3.3.0 requests-oauthlib-1.3.1 tensorboard-2.14.1 tensorboard-data-server-0.7.1 tensorflow-2.14.0 tensorflow-estimator-2.14.0 tensorflow-intel-2.14.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ed60e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_addons\n",
      "  Downloading tensorflow_addons-0.21.0-cp310-cp310-win_amd64.whl (719 kB)\n",
      "     -------------------------------------- 719.8/719.8 kB 4.5 MB/s eta 0:00:00\n",
      "Collecting typeguard<3.0.0,>=2.7\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\sriya nukala\\anaconda3\\lib\\site-packages (from tensorflow_addons) (23.0)\n",
      "Installing collected packages: typeguard, tensorflow_addons\n",
      "Successfully installed tensorflow_addons-0.21.0 typeguard-2.13.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow_addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b44ba68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\sriya nukala\\anaconda3\\lib\\site-packages (from imblearn) (0.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\sriya nukala\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.2.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\sriya nukala\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\sriya nukala\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\sriya nukala\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.10.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\sriya nukala\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.23.5)\n",
      "Installing collected packages: imblearn\n",
      "Successfully installed imblearn-0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52a0f723",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = r'C:\\Users\\Sriya Nukala\\Downloads\\Dataset\\gaussian_filtered_images'\n",
    "filepaths=[]\n",
    "labels=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1553296",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = os.listdir(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab019275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['export.pkl', 'Mild', 'Moderate', 'No_DR', 'Proliferate_DR', 'Severe']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4f5b00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in folds:\n",
    "    foldpath = os.path.join(dataset_path, fold)  \n",
    "    # skip export.pkl file\n",
    "    if pathlib.Path(foldpath).suffix == '':\n",
    "        filelist = os.listdir(foldpath)\n",
    "\n",
    "        for file in filelist:\n",
    "            fpath = os.path.join(foldpath, file)\n",
    "            filepaths.append(fpath)\n",
    "            labels.append(fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d40f42f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = pd.Series(filepaths, name= 'filepaths')\n",
    "img_labels = pd.Series(labels, name='labels')\n",
    "dataset = pd.concat([img_paths, img_labels], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff5a73a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepaths</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\Sriya Nukala\\Downloads\\Dataset\\gaussi...</td>\n",
       "      <td>Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\Sriya Nukala\\Downloads\\Dataset\\gaussi...</td>\n",
       "      <td>Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\Sriya Nukala\\Downloads\\Dataset\\gaussi...</td>\n",
       "      <td>Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\Sriya Nukala\\Downloads\\Dataset\\gaussi...</td>\n",
       "      <td>Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\Sriya Nukala\\Downloads\\Dataset\\gaussi...</td>\n",
       "      <td>Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3657</th>\n",
       "      <td>C:\\Users\\Sriya Nukala\\Downloads\\Dataset\\gaussi...</td>\n",
       "      <td>Severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3658</th>\n",
       "      <td>C:\\Users\\Sriya Nukala\\Downloads\\Dataset\\gaussi...</td>\n",
       "      <td>Severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3659</th>\n",
       "      <td>C:\\Users\\Sriya Nukala\\Downloads\\Dataset\\gaussi...</td>\n",
       "      <td>Severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3660</th>\n",
       "      <td>C:\\Users\\Sriya Nukala\\Downloads\\Dataset\\gaussi...</td>\n",
       "      <td>Severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3661</th>\n",
       "      <td>C:\\Users\\Sriya Nukala\\Downloads\\Dataset\\gaussi...</td>\n",
       "      <td>Severe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3662 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              filepaths  labels\n",
       "0     C:\\Users\\Sriya Nukala\\Downloads\\Dataset\\gaussi...    Mild\n",
       "1     C:\\Users\\Sriya Nukala\\Downloads\\Dataset\\gaussi...    Mild\n",
       "2     C:\\Users\\Sriya Nukala\\Downloads\\Dataset\\gaussi...    Mild\n",
       "3     C:\\Users\\Sriya Nukala\\Downloads\\Dataset\\gaussi...    Mild\n",
       "4     C:\\Users\\Sriya Nukala\\Downloads\\Dataset\\gaussi...    Mild\n",
       "...                                                 ...     ...\n",
       "3657  C:\\Users\\Sriya Nukala\\Downloads\\Dataset\\gaussi...  Severe\n",
       "3658  C:\\Users\\Sriya Nukala\\Downloads\\Dataset\\gaussi...  Severe\n",
       "3659  C:\\Users\\Sriya Nukala\\Downloads\\Dataset\\gaussi...  Severe\n",
       "3660  C:\\Users\\Sriya Nukala\\Downloads\\Dataset\\gaussi...  Severe\n",
       "3661  C:\\Users\\Sriya Nukala\\Downloads\\Dataset\\gaussi...  Severe\n",
       "\n",
       "[3662 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6cd4849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3662 validated image filenames belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size=3662\n",
    "img=224\n",
    "img_size = (224, 224)\n",
    "channels = 3\n",
    "img_shape = (img_size[0], img_size[1], channels)\n",
    "\n",
    "gen=ID()\n",
    "data_gen = gen.flow_from_dataframe( dataset,x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
    "                                    color_mode= 'rgb', shuffle= True, batch_size= batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8493e70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data, img_labels = data_gen.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11da00e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3662, 224, 224, 3) (3662, 5)\n"
     ]
    }
   ],
   "source": [
    "print(img_data.shape, img_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b98d49d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81e54c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split(img_data, img_labels, test_size = 0.25, random_state=42)\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(train_data, train_labels, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cd198a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5405, 224, 224, 3) (5405, 5)\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "\n",
    "train_data1, train_labels1 = sm.fit_resample(train_data.reshape(-1, img * img * 3), train_labels)\n",
    "\n",
    "train_data2 = train_data1.reshape(-1, img, img, 3)\n",
    "\n",
    "print(train_data2.shape, train_labels1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab379021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2300, 224, 224, 3) (2300, 5)\n"
     ]
    }
   ],
   "source": [
    "test_data1, test_labels1 = sm.fit_resample(test_data.reshape(-1, img * img * 3), test_labels)\n",
    "\n",
    "test_data2 = test_data1.reshape(-1, img, img, 3)\n",
    "\n",
    "print(test_data2.shape, test_labels1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37e5b269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1320, 224, 224, 3) (1320, 5)\n"
     ]
    }
   ],
   "source": [
    "val_data1, val_labels1 = sm.fit_resample(val_data.reshape(-1, img * img * 3), val_labels)\n",
    "\n",
    "val_data2 = val_data1.reshape(-1, img, img, 3)\n",
    "\n",
    "print(val_data2.shape, val_labels1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b04b303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5405, 150528)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a421614",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.efficientnet.EfficientNetB3(include_top= False, weights= \"imagenet\", input_shape= img_shape, pooling= 'max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f68edc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    base_model,\n",
    "    BatchNormalization(axis= -1, momentum= 0.99, epsilon= 0.001),\n",
    "    Dense(16, kernel_regularizer= regularizers.l2(l= 0.016), activity_regularizer= regularizers.l1(0.006),\n",
    "                bias_regularizer= regularizers.l1(0.006), activation= 'relu'),\n",
    "    Dropout(rate= 0.45, seed= 123),\n",
    "    Dense(5, activation= 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6241f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetb3 (Functional  (None, 1536)              10783535  \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 1536)              6144      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                24592     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10814356 (41.25 MB)\n",
      "Trainable params: 10723981 (40.91 MB)\n",
      "Non-trainable params: 90375 (353.03 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32f76961",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adamax(learning_rate= 0.001), loss= 'categorical_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a131751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "44/44 [==============================] - 612s 13s/step - loss: 1.9471 - accuracy: 0.5260 - val_loss: 4.1454 - val_accuracy: 0.4891\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - 566s 13s/step - loss: 1.3833 - accuracy: 0.6671 - val_loss: 1.8535 - val_accuracy: 0.6400\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - 582s 13s/step - loss: 1.2276 - accuracy: 0.7199 - val_loss: 1.4597 - val_accuracy: 0.7236\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - 640s 15s/step - loss: 1.1169 - accuracy: 0.7477 - val_loss: 1.3136 - val_accuracy: 0.7509\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - 1323s 30s/step - loss: 1.0303 - accuracy: 0.7851 - val_loss: 1.2100 - val_accuracy: 0.7673\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - 503s 11s/step - loss: 0.9388 - accuracy: 0.8229 - val_loss: 1.2091 - val_accuracy: 0.7745\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - 494s 11s/step - loss: 0.8603 - accuracy: 0.8502 - val_loss: 1.1789 - val_accuracy: 0.7745\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - 491s 11s/step - loss: 0.7932 - accuracy: 0.8725 - val_loss: 1.1715 - val_accuracy: 0.7873\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - 488s 11s/step - loss: 0.7582 - accuracy: 0.8811 - val_loss: 1.1662 - val_accuracy: 0.7909\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - 486s 11s/step - loss: 0.6955 - accuracy: 0.9094 - val_loss: 1.1977 - val_accuracy: 0.7855\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data,train_labels, epochs= 10, verbose= 1, validation_data= (val_data,val_labels), \n",
    "                    validation_steps= None, shuffle= False,batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54682b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 117s 2s/step - loss: 0.5053 - accuracy: 0.9763\n",
      "18/18 [==============================] - 28s 2s/step - loss: 1.1977 - accuracy: 0.7855\n",
      "29/29 [==============================] - 47s 2s/step - loss: 1.1556 - accuracy: 0.7893\n",
      "Training Accuracy: 97.63%\n",
      "Validation Accuracy: 78.55%\n",
      "Testing Accuracy: 78.93%\n"
     ]
    }
   ],
   "source": [
    "train_scores = model.evaluate(train_data, train_labels)\n",
    "val_scores = model.evaluate(val_data, val_labels)\n",
    "test_scores = model.evaluate(test_data,test_labels)\n",
    "\n",
    "print(\"Training Accuracy: %.2f%%\"%(train_scores[1] * 100))\n",
    "print(\"Validation Accuracy: %.2f%%\"%(val_scores[1] * 100))\n",
    "print(\"Testing Accuracy: %.2f%%\"%(test_scores[1] * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
